# Gesture-Based Robotic Arm Control with Artix-7 FPGA

A real-time gesture recognition system that controls a 4-axis robotic arm using hand gestures captured by a camera and processed on Xilinx Artix-7 FPGA.

## ğŸ¯ Project Overview

This project implements a gesture-based robotic arm control system using:
- **Input**: OV7670 camera module for capturing hand gestures
- **Processing**: Real-time image processing on Artix-7 FPGA
- **Output**: VGA display for visual feedback + 4-axis robotic arm control
- **Recognition**: Finger counting algorithm (0-5 fingers) mapped to arm positions

The system first displays the camera feed on a monitor for algorithm verification, then controls the robotic arm based on detected gestures.

## âœ¨ Features

- âœ… Real-time camera image capture (640x480 @ 30 FPS)
- âœ… VGA display output for visual monitoring
- âœ… Gesture recognition (0-5 finger counting)
- âœ… 4-axis servo control for robotic arm
- âœ… Pre-defined gesture-to-motion mapping
- âœ… 10-15 sample dataset support
- âœ… Modular HDL design for easy customization
- ğŸ”® Future: ML hardware accelerator integration

## ğŸ“‹ System Architecture

```
Camera â†’ Image Processing â†’ Gesture Recognition â†’ Servo Control â†’ Robotic Arm
   â†“                                                    
VGA Display (Visual Feedback)
```

**Key Components**:
1. **Camera Interface**: Captures and converts RGB565 to grayscale
2. **Frame Buffer**: Stores image data in dual-port BRAM
3. **VGA Controller**: Displays processed images on monitor
4. **Gesture Recognizer**: Detects finger count using threshold-based algorithm
5. **Servo Controller**: Generates PWM signals for 4 servos
6. **Gesture-to-Servo Mapper**: Maps gestures to arm positions

## ğŸ® Supported Gestures

| Gesture | Fingers | Arm Action |
|---------|---------|------------|
| ğŸ¤› Fist | 0 | Rest position, gripper closed |
| â˜ï¸ Point | 1 | Base left, gripper half-open |
| âœŒï¸ Peace | 2 | Extended upward |
| ğŸ¤Ÿ Three | 3 | Base right |
| ğŸ–– Four | 4 | High position, gripper open |
| âœ‹ Open Hand | 5 | Fully extended, gripper fully open |

## ğŸ› ï¸ Hardware Requirements

- **FPGA Board**: Nexys A7-100T or similar Artix-7 board
- **Camera**: OV7670 camera module (640x480)
- **Display**: VGA monitor
- **Robotic Arm**: 4-axis arm with standard servos (SG90/MG995)
- **Power Supply**: 5V/2A for servos (separate from FPGA)

## ğŸ“ Project Structure

```
Gesture_based_robotic_arm_artix_7/
â”œâ”€â”€ hdl/                          # HDL source files
â”‚   â”œâ”€â”€ camera/                   # Camera interface module
â”‚   â”œâ”€â”€ display/                  # VGA controller & frame buffer
â”‚   â”œâ”€â”€ servo/                    # Servo control module
â”‚   â”œâ”€â”€ gesture/                  # Gesture recognition logic
â”‚   â””â”€â”€ top/                      # Top-level integration
â”œâ”€â”€ testbench/                    # Simulation testbenches
â”œâ”€â”€ constraints/                  # XDC constraint files
â”œâ”€â”€ scripts/                      # Build and simulation scripts
â”œâ”€â”€ datasets/                     # Gesture datasets
â”‚   â””â”€â”€ finger_count/             # Finger count samples
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md           # System architecture details
â”‚   â”œâ”€â”€ HARDWARE_SETUP.md         # Hardware assembly guide
â”‚   â””â”€â”€ USAGE.md                  # Usage instructions
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/sk24ecb0a56-coder/Gesture_based_robotic_arm_artix_7.git
cd Gesture_based_robotic_arm_artix_7
```

### 2. Hardware Setup
Follow the detailed [Hardware Setup Guide](docs/HARDWARE_SETUP.md) to:
- Connect camera module to FPGA
- Connect VGA monitor
- Wire up 4-axis robotic arm with servos
- Configure power supplies

### 3. Build Project
```bash
# Using Vivado in batch mode
vivado -mode batch -source scripts/build.tcl
```

Or open in Vivado GUI and follow [Usage Guide](docs/USAGE.md).

### 4. Program FPGA
```bash
# In Vivado TCL console
open_hw_manager
connect_hw_server
open_hw_target
program_hw_devices
```

### 5. Test System
- Hold hand in front of camera
- Show different finger counts
- Observe arm movements
- Monitor VGA display

## ğŸ“Š Performance

- **Processing**: 100 MHz system clock
- **Frame Rate**: 30 FPS
- **Latency**: < 100ms gesture-to-action
- **Resource Usage**: ~8% LUTs, ~7% BRAM
- **Recognition**: 6 gesture classes (0-5 fingers)

## ğŸ“– Documentation

- **[Architecture](docs/ARCHITECTURE.md)**: Detailed system design and module descriptions
- **[Hardware Setup](docs/HARDWARE_SETUP.md)**: Complete assembly instructions
- **[Usage Guide](docs/USAGE.md)**: Operating instructions and troubleshooting

## ğŸ”¬ Simulation

Run testbenches to verify modules:

```bash
# Run all simulations
vivado -mode batch -source scripts/simulate.tcl
```

Or simulate individual modules in Vivado.

## ğŸ“ Dataset

The project includes a dataset structure for 10-15 samples per gesture:
- Location: `datasets/finger_count/`
- Format: 640x480 grayscale (8-bit RAW)
- Classes: 0-5 fingers

See [Dataset README](datasets/finger_count/README.md) for details.

## ğŸ”® Future Enhancements

### Phase 1 (Current)
- âœ… Basic threshold-based gesture detection
- âœ… Pre-defined servo mappings
- âœ… 10-15 sample dataset

### Phase 2 (Planned)
- [ ] ML hardware accelerator integration
- [ ] CNN-based gesture classification
- [ ] Expanded gesture vocabulary (10+ gestures)
- [ ] Real-time hand tracking
- [ ] Motion gesture recognition
- [ ] On-chip training capability

### Hardware Accelerator Design
The future ML accelerator will include:
- Convolution engine (Conv2D)
- Activation functions (ReLU, Softmax)
- Weight and activation buffers
- Fully connected layers
- Integrated with gesture recognition pipeline

## ğŸ”§ Customization

### Adding New Gestures
1. Modify `hdl/gesture/gesture_recognizer.v`
2. Update `hdl/gesture/gesture_to_servo.v`
3. Collect training samples
4. Test and calibrate

### Adjusting Servo Positions
Edit angle mappings in `hdl/gesture/gesture_to_servo.v`:
```verilog
4'd1: begin  // 1 finger
    servo0_angle <= 8'd45;   // Adjust angles here
    servo1_angle <= 8'd90;
    ...
end
```

## ğŸ› Troubleshooting

Common issues and solutions:

- **Gestures not recognized**: Adjust threshold in gesture_recognizer.v
- **Servo jitter**: Check power supply, add filtering
- **No display**: Verify VGA timing and clock generation
- **Camera not working**: Check connections and power

See [Usage Guide](docs/USAGE.md) for detailed troubleshooting.

## ğŸ“„ License

This project is open-source and available for educational and research purposes.

## ğŸ‘¥ Contributors

- Project developed for Artix-7 FPGA gesture control research

## ğŸ”— References

1. Xilinx Artix-7 FPGAs Documentation
2. OV7670 Camera Module Datasheet
3. VGA Signal Timing Specifications
4. Servo Motor Control Standards

## ğŸ“§ Contact

For questions, issues, or contributions, please open an issue on GitHub.

---

**Note**: This is an educational project demonstrating real-time gesture recognition and robotic control using FPGA technology. The current implementation uses a simple threshold-based algorithm suitable for initial testing with 10-15 samples. Future enhancements will incorporate machine learning hardware acceleration for improved accuracy and expanded gesture vocabulary.
